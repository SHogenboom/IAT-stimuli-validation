---
editor_options: 
  chunk_output_type: console
---
<!--
################################################################################
################################################################################
### LICENSE:                                                                ###
### This code is available under a CC BY-NC-SA 4.0 license                   ###
### https://creativecommons.org/licenses/by-nc-sa/4.0/                       ###
###                                                                          ###
### BY  – Credit must be given to the creator                                ###
### NC  – Only noncommercial uses of the work are permitted                  ###
### SA  – Adaptations must be shared under the same terms                    ###
################################################################################
################################################################################
-->

```{r, pilot-results-text}
pilot_results_text <- results_text(IAT_name = "Gender-Career",
                                   year_of_interest = 2019)
```

We conducted pilot analyses with the data of the GC-IAT to formalize the analyses and reports of the results for individual IATs. `r pilot_results_text$participants_and_responses` `r pilot_results_text$age`.

Figure \@ref(fig:pilot-results-plot) shows the distribution of average response times and error rates across `r n_samples` samples of `r n_subjects_per_sample` participants of the pilot GC-IAT. `r pilot_results_text$RT` `r pilot_results_text$ERROR` `r pilot_results_text$TOTAL`

<center>

```{r, pilot-results-plot, fig.cap = "(ref:results-cap)", include = TRUE}
# Create plot
results_plot(IAT = "Gender-Career",
             year_of_interest = 2019,
             plotHeight = 19.5)

# Include plot in manuscript
knitr::include_graphics(here::here(
  "plots",
  "IATs",
  "Gender-Career_2019.png"
))
```

</center>

(ref:results-cap) The validity estimates per stimulus of the Gender-Career IAT (November - December, 2019). **[RT]** The distribution of *average response time* across `r n_samples` samples of `r n_subjects_per_sample` participants. Within each sample a stimulus (left y-axis) is judged as valid if the average response time is lower than 800 milliseconds (vertical blue line). A stimulus is classed as *reliably* valid (green) if 95% or more of the samples resulted in a valid judgment (right y-axis). Stimuli are considered reliably invalid (red) if a stimulus is classed as valid in 5% or less of the samples. Stimuli that were valid in 6% to 94% of the samples were classed as unreliable (black). **[ERROR]** The distribution of the *percentage of errors* across `r n_samples` samples of `r n_subjects_per_sample` participants. Within each sample a stimulus (left y-axis) is judged as valid if less than 10 percent of the trials were answered incorrectly (vertical blue line). **[TOTAL]** An overview of the validity judgments per exemplar based on average response times (RT) and percentage of errors (ERROR). A stimulus was classed as valid (TOTAL) if both criteria were reliably valid, but as invalid if either criterion was reliably invalid. If the criteria were both unreliable, a stimulus was also classed as unreliable.

The pilot analyses of the GC-IAT showed interesting patterns which served as input for the preregistered analyses (section \@ref(methods-analyses)). First, Figure \@ref(fig:pilot-results-plot) shows that the `RT` and `ERROR` criterion differently conclude stimulus (in)validity. Based on the `RT` criterion Male/Female names are predominantly considered reliably valid (green), whereas Career/Family nouns are predominantly considered reliably invalid (red). This distinction is not evident for the `ERROR` criterion where all stimuli but 'Home' are reliably valid. The distinction is again evident for the `TOTAL` criterion, where the `RT` and `ERROR` validity are combined. Because both criterion must conclude stimulus validity, the criterion with the highest levels of stimulus invalidity - in this case the `RT` criterion - dominates the final validity verdict (`TOTAL`). We report on the `RT` and `ERROR` criterion separately rather than solely on the `TOTAL` to show when conclusions differ.

The pilot results showed three stimuli which specifically stand out. 'Michelle' and 'Daniel' were the only two unreliable stimuli based on the `RT` criterion. The third stimulus, 'Home', was the only not reliably valid stimulus based on the `ERROR` criterion. The fact that individual stimuli could be problematic prompted us to explore whether stimulus (in)validity is consistent across IAT contexts (see section \@ref(results-context-dependency)).

Finally, the difference between the average response times of the Career/Family stimuli (nouns) and the Male/Female stimuli (names) prompted us to preregister the final analysis. In this third analysis we explored the relationship between stimulus validity and stimulus type. We will explore potential explanations when we discuss the results from this analysis.
