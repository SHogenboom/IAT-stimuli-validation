@article{AXT2021,
  title = {The Good and the Bad: {{Are}} Some Attribute Words Better than Others in the {{Implicit Association Test}}?},
  shorttitle = {The Good and the Bad},
  author = {Axt, Jordan R. and Feng, Tony Y. and {Bar-Anan}, Yoav},
  year = {2021},
  month = may,
  journal = {Behavior Research Methods},
  issn = {1554-3528},
  doi = {10.3758/s13428-021-01592-8},
  abstract = {The Implicit Association Test (IAT) is one of the most popular measures in psychological research. A lack of standardization across IATs has resulted in significant variability among stimuli used by researchers, including the positive and negative words used in evaluative IATs. Does the variability in attribute words in evaluative IATs produce unwanted variability in measurement quality across studies? The present work investigated the effect of evaluative stimuli across three studies using 13 IATs and over 60,000 participants. The 64 positive and negative words that we tested provided similar measurement quality. Further, measurement was satisfactory even in IATs that used only category labels as stimuli. These results suggest that common sense is probably a sufficient method for selection of evaluative stimuli in the IAT. For reasonable measurement quality, we recommend that researchers using evaluative IATs in English select words randomly from the set we tested in the present research.},
  langid = {english}
}

@article{BABCHISHIN2013,
  title = {The {{Validity}} of {{Implicit Association Test}} ({{IAT}}) {{Measures}} of {{Sexual Attraction}} to {{Children}}: {{A Meta-Analysis}}},
  shorttitle = {The {{Validity}} of {{Implicit Association Test}} ({{IAT}}) {{Measures}} of {{Sexual Attraction}} to {{Children}}},
  author = {Babchishin, Kelly M. and Nunes, Kevin L. and Hermann, Chantal A.},
  year = {2013},
  month = apr,
  journal = {Archives of Sexual Behavior},
  volume = {42},
  number = {3},
  pages = {487--499},
  issn = {1573-2800},
  doi = {10.1007/s10508-012-0022-8},
  abstract = {The current study presents a quantitative review of the discriminative and convergent validity of Implicit Association Test (IAT) measures adapted to assess sexual interest in children. IAT measures were able to distinguish sex offenders against children (SOC) from non-SOC (M weighted d from random-effects~=~0.63, 95~\% CI [0.42\textendash 0.83], N~=~707, k~=~12). The largest group differences were found between SOC and non-offenders, followed by non-sex offenders and rapists. IAT measures using sex versus not sex (and similar attribute categories, such as sex vs. neutral) provided superior discrimination compared to IAT measures using sexy versus not sexy (and similar attribute categories, such as erotic vs. non-erotic). The IAT measures had a moderate relationship to self-report (r~=~.27, 95~\% CI [.13\textendash.40], N~=~182), sexual offense history variables (r~=~.27, 95~\% CI [.08\textendash.43], N~=~145), and viewing time (r~=~.30, 95~\% CI [.16\textendash.43], N~=~180) measures of sexual interest in children. Although these IAT measures can discriminate between groups and show convergence with other measures of sexual interest, a better understanding of the construct validity of these tools is required before their use in the assessment, treatment, and supervision of sex offenders.},
  langid = {english}
}

@article{BERGER2021,
  title = {``And {{My}} Soul Shall Abhor You'': {{Implicit}} Processing of Social Disgust},
  shorttitle = {``And {{My}} Soul Shall Abhor You''{{11Leviticus}}, 26},
  author = {Berger, Uri and Anaki, David},
  year = {2021},
  month = jan,
  journal = {Personality and Individual Differences},
  volume = {168},
  pages = {110360},
  issn = {0191-8869},
  doi = {10.1016/j.paid.2020.110360},
  abstract = {Disgust has a social component in which others are perceived as more disgusting than the self. Key characteristics of this social component were examined in six experiments. Experiment 1 established the social disgust Implicit Association Test (SD-IAT) applicability for assessing social disgust. Results revealed a congruency effect, in which participants implicitly associated other-race strangers with disgusting stimuli. Experiment 2 explored whether the SD-IAT effect is the result of familiarity. Unfamiliar in-group and out-group members were presented in the IAT. Results were identical to those of Experiment 1. Experiments 3 (using intergroup stimuli) and 4 (using interpersonal stimuli) investigated whether the SD-IAT congruency effect stems from disgust directed at others or from self-liking. Results showed a larger congruency effect for social disgust than for self-liking. Experiments 5 and 6 investigated whether SD stems from an association between the non-self and either disgust or negative valence. Findings showed a larger SD-IAT congruency effect for disgust. The combined results delineate the core aspects of SD and show that it is a heterogeneous phenomenon, based on relative social categories, in which the non-self is perceived as disgusting.},
  langid = {english}
}

@incollection{BICKEL2012,
  title = {Resampling {{Fewer Than}} n {{Observations}}: {{Gains}}, {{Losses}}, and {{Remedies}} for {{Losses}}},
  shorttitle = {Resampling {{Fewer Than}} n {{Observations}}},
  booktitle = {Selected {{Works}} of {{Willem}} van {{Zwet}}},
  author = {Bickel, P. J. and G{\"o}tze, F. and {\noopsort{zwet}}{van Zwet}, W. R.},
  editor = {{\noopsort{geer}}{van de Geer}, Sara and Wegkamp, Marten},
  year = {2012},
  series = {Selected {{Works}} in {{Probability}} and {{Statistics}}},
  pages = {267--297},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4614-1314-1_17},
  abstract = {We discuss a number of resampling schemes in which m = o(n) observations are resampled. We review nonparametric bootstrap failure and give results old and new on how the m out of n with replacement and without replacement bootstraps work. We extend work of Bickel and Yahav (1988) to show that m out of n bootstraps can be made second order correct, if the usual nonparametric bootstrap is correct and study how these extrapolation techniques work when the nonparametric bootstrap does not.},
  isbn = {978-1-4614-1314-1},
  langid = {english}
}

@article{BLUEMKE2006,
  title = {Do Features of Stimuli Influence {{IAT}} Effects?},
  author = {Bluemke, Matthias and Friese, Malte},
  year = {2006},
  month = mar,
  journal = {Journal of Experimental Social Psychology},
  volume = {42},
  number = {2},
  pages = {163--176},
  issn = {0022-1031},
  doi = {10.1016/j.jesp.2005.03.004},
  abstract = {The Implicit Association Test (Greenwald, McGhee, \& Schwartz, 1998) is a categorization task intended to measure the strength of associations between concepts. The present research investigated the influence of individual stimuli on IAT effects. Exploring implicit attitudes of East and West Germans, we systematically manipulated relatedness of target stimuli to the attribute dimension and, simultaneously, relatedness of attribute stimuli to the target dimension. Two experiments demonstrate the influence of stimulus associations as one source that drives IAT effects. Depending on the strength and the direction of these cross-category associations, the result was either stronger IAT effects or a decline of IAT effects. Implications for theoretical models as well as for the interpretation of IAT effects are discussed.},
  langid = {english}
}

@article{BRENDL2001,
  title = {How Do Indirect Measures of Evaluation Work? {{Evaluating}} the Inference of Prejudice in the {{Implicit Association Test}}},
  author = {Brendl, C. Miguel and Markman, Arthur B. and Messner, Claude},
  year = {2001},
  journal = {Journal of Personalily and Social Psychology},
  volume = {81},
  number = {5},
  pages = {760--773},
  doi = {10.1037/0022-3514.81.5.760},
  abstract = {There has been significant interest in indirect measures of attitudes like the lmplicit Association Test (IAT), presumably because of the possibility of uncovering implicit prejudices. The authors derived a set of qualitative predictions for people's performance in the IAT on the basis of random walk models. These were supported in 3 experiments comparing clearly positive or negative categories to nonwords. They also provided evidence that participants shift their response criterion when doing the IAT. Because of these criterion shifts, a response panem in the IAT can have multiple causes. Thus, it is not possible to infer a single cause (such as prejudice) from IAT results. A surprising additional result was that nonwords were treated a. though they were evaluated more negatively than obviously negative items like insects, suggesting that low familiarity items may generate the pattern of data previously interpreted as evidence for implicit prejudice.},
  langid = {english}
}

@article{CARPENTER2019,
  title = {Survey-Software Implicit Association Tests: {{A}} Methodological and Empirical Analysis},
  shorttitle = {Survey-Software Implicit Association Tests},
  author = {Carpenter, Thomas P. and Pogacar, Ruth and Pullig, Chris and Kouril, Michal and Aguilar, Stephen and LaBouff, Jordan and Isenberg, Naomi and Chakroff, Alek},
  year = {2019},
  month = oct,
  journal = {Behavior Research Methods},
  volume = {51},
  number = {5},
  pages = {2194--2208},
  issn = {1554-3528},
  doi = {10.3758/s13428-019-01293-3},
  abstract = {The implicit association test (IAT) is widely used in psychology. Unfortunately, the IAT cannot be run within online surveys, requiring researchers who conduct online surveys to rely on third-party tools. We introduce a novel method for constructing IATs using online survey software (Qualtrics); we then empirically assess its validity. Study 1 (student n = 239) revealed good psychometric properties, expected IAT effects, and expected correlations with explicit measures for survey-software IATs. Study 2 (MTurk n = 818) showed predicted IAT effects across four survey-software IATs (ds = 0.82 [Black\textendash White IAT] to 2.13 [insect\textendash flower IAT]). Study 3 (MTurk n = 270) compared survey-software IATs and IATs run via Inquisit, yielding nearly identical results and intercorrelations that would be expected for identical IATs. Survey-software IATs appear to be reliable and valid, offer numerous advantages, and make IATs accessible for researchers who use survey software to conduct online research. We present all the materials, links to tutorials, and an open-source tool that rapidly automates survey-software IAT construction and analysis.},
  langid = {english}
}

@article{CHARLESWORTH2019,
  title = {Patterns of {{Implicit}} and {{Explicit Attitudes}}: {{I}}. {{Long-Term Change}} and {{Stability From}} 2007 to 2016},
  shorttitle = {Patterns of {{Implicit}} and {{Explicit Attitudes}}},
  author = {Charlesworth, Tessa E. S. and Banaji, Mahzarin R.},
  year = {2019},
  month = feb,
  journal = {Psychological Science},
  volume = {30},
  number = {2},
  pages = {174--192},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1177/0956797618813087},
  abstract = {Using 4.4 million tests of implicit and explicit attitudes measured continuously from an Internet population of U.S. respondents over 13 years, we conducted the first comparative analysis using time-series models to examine patterns of long-term change in six social-group attitudes: sexual orientation, race, skin tone, age, disability, and body weight. Even within just a decade, all explicit responses showed change toward attitude neutrality. Parallel implicit responses also showed change toward neutrality for sexual orientation, race, and skin-tone attitudes but revealed stability over time for age and disability attitudes and change away from neutrality for body-weight attitudes. These data provide previously unavailable evidence for long-term implicit attitude change and stability across multiple social groups; the data can be used to generate and test theoretical predictions as well as construct forecasts of future attitudes.},
  langid = {english}
}

@article{CUCINOTTA2020,
  title = {{{WHO Declares COVID-19}} a {{Pandemic}}},
  author = {Cucinotta, Domenico and Vanelli, Maurizio},
  year = {2020},
  month = mar,
  journal = {Acta Biomedica Atenei Parmensis},
  volume = {91},
  number = {1},
  pages = {157--160},
  issn = {2531-6745},
  doi = {10.23750/abm.v91i1.9397},
  abstract = {The World Health Organization (WHO) on March 11, 2020, has declared the novel coronavirus (COVID-19) outbreak a global pandemic (1). At a news briefing , WHO Director-General, Dr. Tedros Adhanom Ghebreyesus, noted that over the past 2 weeks, the number of cases outside China increased 13-fold and the number of countries with cases increased threefold. Further increases are expected. He said that the WHO is ``deeply concerned both by the alarming levels of spread and severity and by the alarming levels of inaction,'' and he called on countries to take action now to contain the virus. ``We should double down,'' he said. ``We should be more aggressive.'' [...]},
  copyright = {Copyright (c) 2020 Publisher},
  langid = {english}
}

@article{DARLING-HAMMOND2020,
  title = {After ``{{The China Virus}}'' {{Went Viral}}: {{Racially Charged Coronavirus Coverage}} and {{Trends}} in {{Bias Against Asian Americans}}},
  shorttitle = {After ``{{The China Virus}}'' {{Went Viral}}},
  author = {{Darling-Hammond}, Sean and Michaels, Eli K. and Allen, Amani M. and Chae, David H. and Thomas, Marilyn D. and Nguyen, Thu T. and Mujahid, Mahasin M. and Johnson, Rucker C.},
  year = {2020},
  month = dec,
  journal = {Health Education \& Behavior},
  volume = {47},
  number = {6},
  pages = {870--879},
  publisher = {{SAGE Publications Inc}},
  issn = {1090-1981},
  doi = {10.1177/1090198120957949},
  abstract = {On March 8, 2020, there was a 650\% increase in Twitter retweets using the term ``Chinese virus'' and related terms. On March 9, there was an 800\% increase in the use of these terms in conservative news media articles. Using data from non-Asian respondents of the Project Implicit ``Asian Implicit Association Test'' from 2007\textendash 2020 (n = 339,063), we sought to ascertain if this change in media tone increased bias against Asian Americans. Local polynomial regression and interrupted time-series analyses revealed that Implicit Americanness Bias\textemdash or the subconscious belief that European American individuals are more ``American'' than Asian American individuals\textemdash declined steadily from 2007 through early 2020 but reversed trend and began to increase on March 8, following the increase in stigmatizing language in conservative media outlets. The trend reversal in bias was more pronounced among conservative individuals. This research provides evidence that the use of stigmatizing language increased subconscious beliefs that Asian Americans are ``perpetual foreigners.'' Given research that perpetual foreigner bias can beget discriminatory behavior and that experiencing discrimination is associated with adverse mental and physical health outcomes, this research sounds an alarm about the effects of stigmatizing media on the health and welfare of Asian Americans.},
  langid = {english}
}

@article{DEHOUWER2001,
  title = {A {{Structural}} and {{Process Analysis}} of the {{Implicit Association Test}}},
  author = {De Houwer, Jan},
  year = {2001},
  month = nov,
  journal = {Journal of Experimental Social Psychology},
  volume = {37},
  number = {6},
  pages = {443--451},
  issn = {0022-1031},
  doi = {10.1006/jesp.2000.1464},
  abstract = {The Implicit Association Test (IAT) is based on the observation that participants find it easier to respond in the same way to exemplars of two concepts when these concepts are similar (e.g., ``positive'' and ``flower'') compared to when the concepts are dissimilar (e.g., ``positive'' and ``insect''). In the first part of this article, I argue that the IAT is structurally similar to stimulus\textendash response compatibility tasks. On the basis of this analogy, I then present two response conflict accounts of IAT effects. The data of an experiment that was designed to test these accounts showed that IAT effects reflect attitudes toward the target concepts rather than attitudes toward the individual exemplars of those concepts. The results shed light on the processes that underlie IAT effects, suggest that automatic attitude activation may depend on the construal of the object that is fostered by the context, and clarify the relation between different indirect measures of attitudes.},
  langid = {english}
}

@article{DELEEUW2015,
  title = {{{jsPsych}}: {{A JavaScript}} Library for Creating Behavioral Experiments in a {{Web}} Browser},
  shorttitle = {{{jsPsych}}},
  author = {{\noopsort{leeuw}}{de Leeuw}, Joshua R.},
  year = {2015},
  month = mar,
  journal = {Behavior Research Methods},
  volume = {47},
  number = {1},
  pages = {1--12},
  issn = {1554-3528},
  doi = {10.3758/s13428-014-0458-y},
  abstract = {Online experiments are growing in popularity, and the increasing sophistication of Web technology has made it possible to run complex behavioral experiments online using only a Web browser. Unlike with offline laboratory experiments, however, few tools exist to aid in the development of browser-based experiments. This makes the process of creating an experiment slow and challenging, particularly for researchers who lack a Web development background. This article introduces jsPsych, a JavaScript library for the development of Web-based experiments. jsPsych formalizes a way of describing experiments that is much simpler than writing the entire experiment from scratch. jsPsych then executes these descriptions automatically, handling the flow from one task to another. The jsPsych library is open-source and designed to be expanded by the research community. The project is available online at www.jspsych.org.},
  langid = {english}
}

@article{SCHIMMACK2021,
  title = {The Implicit Association Test: {{A}} Method in Search of a Construct},
  author = {Schimmack, Ulrich},
  year = {2021},
  journal = {Perspectives on Psychological Science},
  volume = {16},
  number = {2},
  eprint = {https://doi.org/10.1177/1745691619863798},
  pages = {396--414},
  doi = {10.1177/1745691619863798},
  abstract = {In 1998, Greenwald, McGhee, and Schwartz proposed that the Implicit Association Test (IAT) measures individual differences in implicit social cognition. This claim requires evidence of construct validity. I review the evidence and show that there is insufficient evidence for this claim. Most important, I show that few studies were able to test discriminant validity of the IAT as a measure of implicit constructs. I examine discriminant validity in several multimethod studies and find little or no evidence of discriminant validity. I also show that validity of the IAT as a measure of attitudes varies across constructs. Validity of the self-esteem IAT is low, but estimates vary across studies. About 20\% of the variance in the race IAT reflects racial preferences. The highest validity is obtained for measuring political orientation with the IAT (64\%). Most of this valid variance stems from a distinction between individuals with opposing attitudes, whereas reaction times contribute less than 10\% of variance in the prediction of explicit attitude measures. In all domains, explicit measures are more valid than the IAT, but the IAT can be used as a measure of sensitive attitudes to reduce measurement error by using a multimethod measurement model.}
}

@article{FAZIO1995,
  title = {Variability in Automatic Activation as an Unobtrusive Measure of Racial Attitudes: {{A}} Bona Fide Pipeline?},
  shorttitle = {Variability in Automatic Activation as an Unobtrusive Measure of Racial Attitudes},
  author = {Fazio, Russell H. and Jackson, Joni R. and Dunton, Bridget C. and Williams, Carol J.},
  year = {1995},
  month = dec,
  journal = {Journal of Personality and Social Psychology},
  volume = {69},
  number = {6},
  pages = {1013--1027},
  issn = {1939-1315, 0022-3514},
  doi = {10.1037/0022-3514.69.6.1013},
  abstract = {The research examines an unobtrusive measure of racial attitudes based on the evaluations that are automatically activated from memory on the presentation of Black versus White faces. Study 1, which concerned the technique's validity, obtained different attitude estimates for Black and White participants and also revealed that the variability among White participants was predictive of other race-related judgments and behavior. Study 2 concerned the lack of correspondence between the unobtrusive estimates and Modern Racism Scale (MRS) scores. The reactivity of the MRS was demonstrated in Study 3. Study 4 observed an interaction between the unobtrusive estimates and an individual difference in motivation to control prejudiced reactions when predicting MRS scores. The theoretical implications of the findings for consideration of automatic and controlled components of racial prejudice are discussed, as is the status of the MRS},
  langid = {english}
}

@article{FISHER1993,
  title = {Social {{Desirability Bias}} and the {{Validity}} of {{Indirect Questioning}}},
  author = {Fisher, Robert J.},
  year = {1993},
  month = sep,
  journal = {Journal of Consumer Research},
  volume = {20},
  number = {2},
  pages = {303--315},
  issn = {0093-5301},
  doi = {10.1086/209351},
  abstract = {Indirect (i.e., structured projective) questioning has been employed frequently in marketing and other social sciences to reduce social desirability bias, that is, systematic error in self-report measures resulting from the desire of respondents to avoid embarrassment and project a favorable image to others. Yet little is known about the validity of indirect questioning in reducing social desirability bias. This article reports on three studies that examine indirect questioning as a technique to reduce social desirability bias on self-report measures. The effects of asking indirect (i.e., structured, projective) questions were compared with direct (i.e., structured, personal) questions. The pattern of results indicates that indirect questioning reduces social desirability bias on variables subject to social influence and has no significant effect on socially neutral variables. The social nature of the differences between direct and indirect questioning groups, and the attribution of an undesirable trait to an out-group but not an in-group target, supports the view that subjects projected their beliefs and evaluations in the indirect response situation. These results are consistent across several product categories and indirect question wordings.}
}

@inproceedings{GARIMELLA2017,
  title = {Demographic-Aware Word Associations},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  author = {Garimella, Aparna and Banea, Carmen and Mihalcea, Rada},
  year = {2017},
  month = sep,
  pages = {2285--2295},
  publisher = {{Association for Computational Linguistics}},
  address = {{Copenhagen, Denmark}},
  doi = {10.18653/v1/D17-1242},
  abstract = {Variations of word associations across different groups of people can provide insights into people's psychologies and their world views. To capture these variations, we introduce the task of demographic-aware word associations. We build a new gold standard dataset consisting of word association responses for approximately 300 stimulus words, collected from more than 800 respondents of different gender (male/female) and from different locations (India/United States), and show that there are significant variations in the word associations made by these groups. We also introduce a new demographic-aware word association model based on a neural net skip-gram architecture, and show how computational methods for measuring word associations that specifically account for writer demographics can outperform generic methods that are agnostic to such information.}
}

@article{GAST2010,
  title = {When Old and Frail Is Not the Same: {{Dissociating}} Category and Stimulus Effects in Four Implicit Attitude Measurement Methods},
  shorttitle = {When Old and Frail Is Not the Same},
  author = {Gast, Anne and Rothermund, Klaus},
  year = {2010},
  month = mar,
  journal = {Quarterly Journal of Experimental Psychology},
  volume = {63},
  number = {3},
  pages = {479--498},
  publisher = {{SAGE Publications}},
  issn = {1747-0218},
  doi = {10.1080/17470210903049963},
  abstract = {It is not always clear whether implicit attitude measures assess the attitude towards single stimuli or the attitude towards categories. Nevertheless, this is important to know\textemdash both for interpreting implicit attitude effects and for selecting the test that is most appropriate for individual research aims. We investigated this for four implicit measures: the standard Implicit Association Test (IAT), the IAT-recoding free (IAT-RF), and two versions of the Extrinsic Affective Simon Task (EAST, identification (ID)-EAST). Effects in the standard IAT reflect evaluations of categories and single stimuli, whereas the IAT-RF measures attitudes towards categories only. Both versions of the EAST measure evaluations of single stimuli independently from the evaluation of categories. Three different effect sources are distinguished: attitudes towards single stimuli (IAT; EAST and ID-EAST), attitudes towards target categories (IAT and IAT-RF), and processes of recoding (IAT), which do not necessarily reflect attitudes.},
  langid = {english}
}

@article{GAWRONSKI2009,
  title = {Ten Frequently Asked Questions about Implicit Measures and Their Frequently Supposed, but Not Entirely Correct Answers.},
  author = {Gawronski, Bertram},
  year = {2009},
  month = aug,
  journal = {Canadian Psychology/Psychologie canadienne},
  volume = {50},
  number = {3},
  pages = {141--150},
  issn = {1878-7304, 0708-5591},
  doi = {10.1037/a0013848},
  abstract = {Self-report measures are often criticised for their susceptibility to self-presentation and their inability to capture mental contents that are inaccessible to introspection. Over the past decade, researchers have attempted to overcome these problems by means of implicit measures, which infer mental contents from participants' performance on experimental paradigms. In the present article I provide an overview of the currently available implicit measures and discuss 10 common assumptions about these measures. I argue that many of these assumptions are either inconsistent with the available evidence or theoretically problematic for conceptual reasons. Nevertheless, implicit measures have proven their usefulness in predicting behaviours that are difficult to predict with traditional self-report measures. Thus, even though implicit measures may not be able to provide the information that is sometimes attributed to these measures, they represent a valuable addition to the toolbox of psychological instruments in understanding the determinants of human behaviour.},
  langid = {english}
}

@article{GREENWALD1998,
  title = {Measuring Individual Differences in Implicit Cognition: {{The}} Implicit Association Test.},
  author = {Greenwald, A.G. and McGhee, D.E. and Schwartz, J.L.K.},
  year = {1998},
  journal = {Journal of Personality and Social Psychology},
  volume = {74},
  number = {6},
  pages = {1464--1480},
  doi = {10.1037/0022-3514.74.6.1464},
  abstract = {An implicit association test (IAT) measures differential association of 2 target concepts with an attribute. The 2 concepts appear in a 2-choice task (e.g., flower vs. insect names), and the attribute in a 2nd task (e.g., pleasant vs. unpleasant words for an evaluation attribute). When instructions oblige highly associated categories (e.g., flower + pleasant) to share a response key, performance is faster than when less associated categories (e.g., insect + pleasant) share a key. This performance difference implicitly measures differential association of the 2 concepts with the attribute. In 3 experiments, the IAT was sensitive to (a) near-universal evaluative differences (e.g., flower vs. insect), (b) expected individual differences in evaluative associations (Japanese + pleasant vs. Korean + pleasant for Japanese vs. Korean subjects), and (c) consciously disavowed evaluative differences (Black + pleasant vs. White + pleasant for self-described unprejudiced White subjects).},
  langid = {english}
}

@article{GREENWALD2003,
  title = {Understanding and Using the {{Implicit Association Test}}: {{I}}. {{An}} Improved Scoring Algorithm},
  author = {Greenwald, A. G. and Nosek, B. A. and Banaji, M. R.},
  year = {2003},
  journal = {Journal of Personality and Social Psychology},
  volume = {85},
  number = {2},
  pages = {197--216},
  doi = {10.1037/0022-3514.85.2.197},
  abstract = {[Correction Notice: An erratum for this article was reported in Vol 85(3) of Journal of Personality and Social Psychology (see record 2007-16878-001). The article contained several errors. On page 203, the data lines in Figure 2 are incorrectly labeled. As in Figure 1, the line with filled squares as data points should be labeled MEAN, the line with filled diamonds as data points should be labeled MEDIAN, and the line with unfilled squares as data points should be labeled RECIPROCAL.] In reporting Implicit Association Test (IAT) results, researchers have most often used scoring conventions described in the first publication of the IAT (A. G. Greenwald, D. E. McGhee, \& J. L. K. Schwartz, 1998). Demonstration IATs available on the Internet have produced large data sets that were used in the current article to evaluate alternative scoring procedures. Candidate new algorithms were examined in terms of their (a) correlations with parallel self-report measures, (b) resistance to an artifact associated with speed of responding, (c) internal consistency, (d) sensitivity to known influences on IAT measures, and (e) resistance to known procedural influences. The best-performing measure incorporates data from the IAT's practice trials, uses a metric that is calibrated by each respondent's latency variability, and includes a latency penalty for errors. This new algorithm strongly outperforms the earlier (conventional) procedure.}
}

@article{GREENWALD2009,
  title = {Understanding and {{Using}} the {{Implicit Association Test}}: {{III}}. {{Meta-Analysis}} of {{Predictive Validity}}},
  author = {Greenwald, A. G. and Poehlman, T Andrew and Uhlmann, Eric Luis and Banaji, Mahzarin R},
  year = {2009},
  journal = {Journal of Personality and Social Psychology},
  volume = {97},
  number = {1},
  pages = {17--41},
  doi = {10.1037/a0015575},
  abstract = {This review of 122 research reports (184 independent samples, 14,900 subjects) found average r ϭ .274 for prediction of behavioral, judgment, and physiological measures by Implicit Association Test (IAT) measures. Parallel explicit (i.e., self-report) measures, available in 156 of these samples (13,068 subjects), also predicted effectively (average r ϭ .361), but with much greater variability of effect size. Predictive validity of self-report was impaired for socially sensitive topics, for which impression management may distort self-report responses. For 32 samples with criterion measures involving Black\textendash White interracial behavior, predictive validity of IAT measures significantly exceeded that of self-report measures. Both IAT and self-report measures displayed incremental validity, with each measure predicting criterion variance beyond that predicted by the other. The more highly IAT and self-report measures were intercorrelated, the greater was the predictive validity of each.},
  langid = {english}
}

@misc{GREENWALD2020,
  title = {The {{Implicit Association Test}} at Age 20: {{What}} Is Known and What Is Not Known about Implicit Bias},
  shorttitle = {The {{Implicit Association Test}} at Age 20},
  author = {Greenwald, A. G. and Brendl, Miguel and Cai, Huajian and Cvencek, Dario and Dovidio, John and Friese, Malte and Hahn, Adam and Hehman, Eric and Hofmann, Wilhelm and Hughes, Sean and Hussey, Ian and Jordan, Christian H. and Jost, John and Kirby, Teri A. and Lai, Calvin K. and Lang, Jonas W. B. and Lindgren, Kristen P. and Maison, Dominika and Ostafin, Brian and Rae, James R. and Ratliff, Kate and Smith, Colin and Spruyt, Adriaan and Wiers, Reinout},
  year = {2020},
  month = apr,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/bf97c},
  abstract = {[Version 3 (uploaded 21 April 2020) provides corrected list of co-authors and commenters; the ms. is otherwise unchanged from Versions 1 and 2.]     Scientific interest in unintended discrimination that can result from implicit attitudes and stereotypes (implicit biases) has produced a large corpus of empirical findings. In addition to much evidence for validity and usefulness of Implicit Association Test (IAT) measures, there have been psychological critiques of empirical findings and theoretical disagreements about interpretation of IAT findings. Because of public attention drawn by the concept of implicit bias, commercial and other applications based on the concept of implicit bias have been developed by non-psychologists\textemdash some of these applications are not appropriately guided by the existing body of research findings. This article is in 5 parts: (1) review of best practices for research use of IAT measures, (2) summary of what has been confidently learned from empirical research using IAT measures, (3) accepted and controversial theoretical interpretations of IAT findings, (4) significant questions about the IAT and implicit bias that still await answer, and (5) questions arising in attempts to apply research findings to remedy unintended discrimination due to implicit biases.}
}

@article{GREENWALD2021,
  title = {Best Research Practices for Using the {{Implicit Association Test}}},
  author = {Greenwald, A. G. and Brendl, Miguel and Cai, Huajian and Cvencek, Dario and Dovidio, John F. and Friese, Malte and Hahn, Adam and Hehman, Eric and Hofmann, Wilhelm and Hughes, Sean and Hussey, Ian and Jordan, Christian and Kirby, Teri A. and Lai, Calvin K. and Lang, Jonas W. B. and Lindgren, Kristen P. and Maison, Dominika and Ostafin, Brian D. and Rae, James R. and Ratliff, Kate A. and Spruyt, Adriaan and Wiers, Reinout W.},
  year = {2021},
  month = sep,
  journal = {Behavior Research Methods},
  issn = {1554-3528},
  doi = {10.3758/s13428-021-01624-3},
  abstract = {Interest in unintended discrimination that can result from implicit attitudes and stereotypes (implicit biases) has stimulated many research investigations. Much of this research has used the Implicit Association Test (IAT) to measure association strengths that are presumed to underlie implicit biases. It had been more than a decade since the last published treatment of recommended best practices for research using IAT measures. After an initial draft by the first author, and continuing through three subsequent drafts, the 22 authors and 14 commenters contributed extensively to refining the selection and description of recommendation-worthy research practices. Individual judgments of agreement or disagreement were provided by 29 of the 36 authors and commenters. Of the 21 recommended practices for conducting research with IAT measures presented in this article, all but two were endorsed by 90\% or more of those who felt knowledgeable enough to express agreement or disagreement; only 4\% of the totality of judgments expressed disagreement. For two practices that were retained despite more than two judgments of disagreement (four for one, five for the other), the bases for those disagreements are described in presenting the recommendations. The article additionally provides recommendations for how to report procedures of IAT measures in empirical articles.},
  langid = {english}
}

@article{HEHMAN2019,
  title = {Establishing Construct Validity Evidence for Regional Measures of Explicit and Implicit Racial Bias.},
  author = {Hehman, Eric and Calanchini, Jimmy and Flake, Jessica K. and Leitner, Jordan B.},
  year = {2019},
  month = jun,
  journal = {Journal of Experimental Psychology: General},
  volume = {148},
  number = {6},
  pages = {1022--1040},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/xge0000623},
  abstract = {Large-scale data collection has enabled social scientists to examine psychological constructs at broad, regional levels. However, because constructs and their measures initially operationalized at the individual level may have qualitatively and quantitatively different properties at other levels of analysis, the validity of constructs must be established when they are operationalized at new levels. To this end, the current research presents evidence of construct validity for explicit and implicit racial bias at region levels. Following classic measurement theory, we examine the substantive, structural, and external evidence of construct validity for regional biases. We do so with responses from ϳ2 million Black and White North Americans collected over 13 years. Though implicit measures typically demonstrate low retest reliability at the individual level, our analyses reveal conventionally acceptable levels of retest reliability at the highest levels of regional aggregation. Additionally, whereas previous meta-analyses find relatively low explicit\textendash implicit correlations at the individual level, the present research uncovered strong explicit\textendash implicit correlations at regional levels. The findings have implications for how we interpret measures of racial bias at regional levels.},
  langid = {english}
}

@article{HEIPHETZ2013,
  title = {Patterns of {{Implicit}} and {{Explicit Attitudes}} in {{Children}} and {{Adults}}: {{Tests}} in the {{Domain}} of {{Religion}}},
  shorttitle = {Patterns of {{Implicit}} and {{Explicit Attitudes}} in {{Children}} and {{Adults}}},
  author = {Heiphetz, Larisa and Spelke, Elizabeth S. and Banaji, Mahzarin R.},
  year = {2013},
  month = aug,
  journal = {Journal of experimental psychology. General},
  volume = {142},
  number = {3},
  pages = {864--879},
  issn = {0096-3445},
  doi = {10.1037/a0029714},
  abstract = {Among the most replicated results in social cognition is the split between explicit and implicit attitudes; adults demonstrate weaker group-based preferences on explicit rather than implicit measures. However, the developmental origins of this pattern remain unclear. If implicit attitudes develop over a protracted period of time, children should not demonstrate the implicit preferences observed among adults. Additionally, unlike adults, children may report group-based preferences due to their lesser concern with social desirability. In Study 1, Christian adults showed the expected pattern of robust implicit preference but no explicit preference. In four additional experiments, 6\textendash 8 year old children whose parents identified them as Christian viewed characters described as belonging to two starkly different religious groups (``strong religious difference'') or two relatively similar religious groups (``weak religious difference''). Participants then completed explicit and implicit (IAT) measures of attitude toward Christians and either Hindus (Study 2) or Jews (Studies 3\textendash 5). Three main results emerged. First, like adults, children showed significant implicit pro-Christian preferences across all studies. Second, unlike adults, children in the ``strong religious difference'' case reported preferences of approximately the same magnitude as their implicit attitudes (i.e., no dissociation). Third, even in the ``weak religious difference'' case, children showed implicit pro-Christian preferences (although, like adults, their explicit attitudes were not sensitive to intergroup difference). These data suggest that the seeds of implicit religious preferences are sown early and that children's explicit preferences are influenced by the social distance between groups.},
  pmcid = {PMC3594419},
  pmid = {22905875}
}

@article{HEITZ2014,
  title = {The Speed-Accuracy Tradeoff: History, Physiology, Methodology, and Behavior},
  shorttitle = {The Speed-Accuracy Tradeoff},
  author = {Heitz, Richard P.},
  year = {2014},
  journal = {Frontiers in Neuroscience},
  volume = {8},
  issn = {1662-453X},
  abstract = {There are few behavioral effects as ubiquitous as the speed-accuracy tradeoff (SAT). From insects to rodents to primates, the tendency for decision speed to covary with decision accuracy seems an inescapable property of choice behavior. Recently, the SAT has received renewed interest, as neuroscience approaches begin to uncover its neural underpinnings and computational models are compelled to incorporate it as a necessary benchmark. The present work provides a comprehensive overview of SAT. First, I trace its history as a tractable behavioral phenomenon and the role it has played in shaping mathematical descriptions of the decision process. Second, I present a ``users guide'' of SAT methodology, including a critical review of common experimental manipulations and analysis techniques and a treatment of the typical behavioral patterns that emerge when SAT is manipulated directly. Finally, I review applications of this methodology in several domains.}
}

@article{HOFMANN2005,
  title = {A {{Meta-Analysis}} on the {{Correlation Between}} the {{Implicit Association Test}} and {{Explicit Self-Report Measures}}},
  author = {Hofmann, Wilhelm and Gawronski, Bertram and Gschwendner, Tobias and Le, Huy and Schmitt, Manfred},
  year = {2005},
  month = oct,
  journal = {Personality and Social Psychology Bulletin},
  volume = {31},
  number = {10},
  pages = {1369--1385},
  publisher = {{SAGE Publications Inc}},
  issn = {0146-1672},
  doi = {10.1177/0146167205275613},
  abstract = {Theoretically, low correlations between implicit and explicit measures can be due to (a) motivational biases in explicit self reports, (b) lack of introspective access to implicitly assessed representations, (c) factors influencing the retrieval of information from memory, (d) method-related characteristics of the two measures, or (e) complete independence of the underlying constructs. The present study addressed these questions from a meta-analytic perspective, investigating the correlation between the Implicit Association Test (IAT) and explicit self-report measures. Based on a sample of 126 studies, the mean effect size was .24, with approximately half of the variability across correlations attributable to moderator variables. Correlations systematically increased as a function of (a) increasing spontaneity of self-reports and (b) increasing conceptual correspondence between measures. These results suggest that implicit and explicit measures are generally related but that higher order inferences and lack of conceptual correspondence can reduce the influence of automatic associations on explicit self-reports.},
  langid = {english}
}

@misc{MEADE2018,
  title = {{{FreeIAT Home}}},
  author = {Meade, Adam W.},
  year = {2018},
  month = may,
  abstract = {The~FreeIAT was created to provide a free, open-source alternative to commercial software used to administer the Implicit Association Test.~The FreeIAT is intended for Psychologists and others with\ldots},
  langid = {american}
}

@misc{MILLER2018,
  type = {Blog},
  title = {Mixed {{Effects Modeling Tips}}: {{Use}} a {{Fast Optimizer}}, but {{Perform Optimizer Checks}}},
  shorttitle = {Mixed {{Effects Modeling Tips}}},
  author = {Miller, Steven},
  year = {2018},
  journal = {Steven V. Miller},
  howpublished = {http://svmiller.com/blog/2018/06/mixed-effects-models-optimizer-checks/}
}

@article{NILLESEN2021,
  title = {On the Malleability of Gender Attitudes: {{Evidence}} from Implicit and Explicit Measures in {{Tunisia}}},
  shorttitle = {On the Malleability of Gender Attitudes},
  author = {Nillesen, Eleonora and Grimm, Michael and Goedhuys, Micheline and Reitmann, Ann-Kristin and Meysonnat, Aline},
  year = {2021},
  month = feb,
  journal = {World Development},
  volume = {138},
  pages = {105263},
  issn = {0305-750X},
  doi = {10.1016/j.worlddev.2020.105263},
  abstract = {In many regions of the world, significant parts of society are persistently unsupportive of female empowerment. The role of women is often still defined by social norms, rather than legal rights, hampering economic development. Women's empowerment has therefore become a top priority on development agendas, also testified by an increasing number of policy interventions aiming to promote gender equality. To monitor progress in this area we need reliable data on gender attitudes. However, standard self-reported measures of gender attitudes are prone to a wide range of measurement errors and social desirability bias. In this paper we address this problem and use a new field application of the implicit association test (IAT), next to a set of standard survey questions, to measure implicit gender attitudes in Tunisia. Implicit attitudes are considered less susceptible to measurement bias and may serve to more accurately assess gender attitudes. Further, we examine the malleability of implicit gender attitudes using a randomized video intervention illustrating real-life gender reforms in Tunisia, and natural variation in interviewer characteristics with respect to gender and perceived religiosity. Our study finds that the video has no average impact on implicit (IAT-based) attitudes, which is consistent with the idea that in a highly polarized society like Tunisia such an intervention only affects specific groups in a society. We indeed find that the video mitigates the implicit gender bias only among the specific subpopulation of conservative women. We also confirm the presence of interviewer effects. Yet, impacts are more pronounced for explicit attitudes, which may suggest social desirability at work in surveys. We believe that our study may inform policymakers on the potential power of light interventions and helps improve measurements related to gender norms and attitudes.},
  langid = {english}
}

@article{NOSEK2005,
  title = {Understanding and {{Using}} the {{Implicit Association Test}}: {{II}}. {{Method Variables}} and {{Construct Validity}}},
  shorttitle = {Understanding and {{Using}} the {{Implicit Association Test}}},
  author = {Nosek, Brian A. and Greenwald, A. G. and Banaji, Mahzarin R.},
  year = {2005},
  month = feb,
  journal = {Personality and Social Psychology Bulletin},
  volume = {31},
  number = {2},
  pages = {166--180},
  publisher = {{SAGE Publications Inc}},
  issn = {0146-1672},
  doi = {10.1177/0146167204271418},
  abstract = {The Implicit Association Test (IAT) assesses relative strengths of four associations involving two pairs of contrasted concepts (e.g., male-female and family-career). In four studies, analyses of data from 11 Web IATs, averaging 12,000 respondents per data set, supported the following conclusions: (a) sorting IAT trials into subsets does not yield conceptually distinct measures; (b) valid IAT measures can be produced using as few as two items to represent each concept; (c) there are conditions for which the administration order of IAT and self-report measures does not alter psychometric properties of either measure; and (d) a known extraneous effect of IAT task block order was sharply reduced by using extra practice trials. Together, these analyses provide additional construct validation for the IAT and suggest practical guidelines to users of the IAT.},
  langid = {english}
}

@article{OSWALD2013,
  title = {Predicting {{Ethnic}} and {{Racial Discrimination}}: {{A Meta-Analysis}} of {{IAT Criterion Studies}}},
  author = {Oswald, Frederick L and Mitchell, Gregory and Blanton, Hart and Jaccard, James and Tetlock, Philip E},
  year = {2013},
  journal = {Journal of Personality and Social Psychology},
  volume = {105},
  number = {2},
  pages = {171--192},
  doi = {10.1037/a0032734},
  abstract = {This article reports a meta-analysis of studies examining the predictive validity of the Implicit Association Test (IAT) and explicit measures of bias for a wide range of criterion measures of discrimination. The meta-analysis estimates the heterogeneity of effects within and across 2 domains of intergroup bias (interracial and interethnic), 6 criterion categories (interpersonal behavior, person perception, policy preference, microbehavior, response time, and brain activity), 2 versions of the IAT (stereotype and attitude IATs), 3 strategies for measuring explicit bias (feeling thermometers, multi-item explicit measures such as the Modern Racism Scale, and ad hoc measures of intergroup attitudes and stereotypes), and 4 criterion-scoring methods (computed majority\textendash minority difference scores, relative majority\textendash minority ratings, minority-only ratings, and majority-only ratings). IATs were poor predictors of every criterion category other than brain activity, and the IATs performed no better than simple explicit measures. These results have important implications for the construct validity of IATs, for competing theories of prejudice and attitude\textendash behavior relations, and for measuring and modeling prejudice and discrimination.},
  langid = {english}
}

@article{POWELL2009,
  title = {The {{BOBYQA}} Algorithm for Bound Constrained Optimization without Derivatives},
  author = {Powell, M J D},
  year = {2009},
  pages = {39},
  abstract = {BOBYQA is an iterative algorithm for finding a minimum of a function F(x), x{$\in$}Rn , subject to bounds a{$\leq$}x{$\leq$}b on the variables, F being specified by a ``black box'' that returns the value F(x) for any feasible x. Each iteration employs a quadratic approximation Q to F that satisfies Q(y j ) = F(y j ), j = 1, 2, . . . , m, the interpolation points y j being chosen and adjusted automatically, but m is a prescribed constant, the value m = 2n+1 being typical. These conditions leave much freedom in Q, taken up when the model is updated by the highly successful technique of minimizing the Frobenius norm of the change to the second derivative matrix of Q. Thus no first derivatives of F are required explicitly. Most changes to the variables are an approximate solution to a trust region subproblem, using the current quadratic model, with a lower bound on the trust region radius that is reduced cautiously, in order to keep the interpolation points well separated until late in the calculation, which lessens damage from computer rounding errors. Some other changes to the variables are designed to improve the model without reducing F. These techniques are described. Other topics include the starting procedure that is given an initial vector of variables, the value of m and the initial trust region radius. There is also a new device called RESCUE that tries to restore normality if severe loss of accuracy occurs in the matrix calculations of the updating of the model. Numerical results are reported and discussed for two test problems, the numbers of variables being between 10 and 320.},
  langid = {english}
}

@article{QIAN2021,
  title = {Age-Related Differences in Implicit and Explicit Racial Biases in {{Cameroonians}}},
  author = {Qian, Miao and Heyman, Gail D. and Quinn, Paul C. and Messi, Francoise A. and Fu, Genyue and Lee, Kang},
  year = {2021},
  journal = {Developmental Psychology},
  volume = {57},
  number = {3},
  pages = {386--396},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-0599},
  doi = {10.1037/dev0001149},
  abstract = {Age-related differences in explicit and implicit racial biases in Black Cameroonians (N = 187, 94 females) were investigated using a cross-sectional design. Participants ranged in age from 3 to 30 years, and were from middle-to-high income families in Yaound\'e, Cameroon. Biases were assessed by comparing attitudes toward Blacks with those toward Whites and Chinese. Implicit pro-Black/anti-other-race (White and Chinese) biases were present at age 4, in contrast to anti-Black/pro-other-race biases, which were observed among 9- to 30-year-olds. In addition, explicit pro-Black/anti-other-race biases that were present at age 4 were no longer evident by age 7. These findings provide a detailed picture of age-related differences in racial biases in an understudied part of the world that can inform theories regarding the development of racial biases, as well as efforts to reduce such biases. (PsycInfo Database Record (c) 2021 APA, all rights reserved)}
}

@incollection{RATLIFF2021,
  title = {Lessons from Two Decades of {{Project Implicit}}},
  booktitle = {The {{Cambridge}} Handbook of Implicit Bias and Racism},
  author = {Ratliff, Kate A. and Smith, Colin T.},
  year = {2021, in press},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge, England}},
  langid = {english}
}

@article{RAVARY2019,
  title = {Shaping the {{Body Politic}}: {{Mass Media Fat-Shaming Affects Implicit Anti-Fat Attitudes}}},
  shorttitle = {Shaping the {{Body Politic}}},
  author = {Ravary, Amanda and Baldwin, Mark W. and Bartz, Jennifer A.},
  year = {2019},
  month = nov,
  journal = {Personality and Social Psychology Bulletin},
  volume = {45},
  number = {11},
  pages = {1580--1589},
  publisher = {{SAGE Publications Inc}},
  issn = {0146-1672},
  doi = {10.1177/0146167219838550},
  abstract = {The human psyche is profoundly shaped by its cultural milieu; however, few studies have examined the dynamics of cultural influence in everyday life, especially when it comes to shaping people's automatic, implicit attitudes. In this quasi-experimental field study, we investigated the effect of transient, but salient, cultural messages\textemdash the pop-cultural phenomenon of celebrity ``fat-shaming''\textemdash on implicit anti-fat attitudes in the population. Adopting the ``copycat suicide'' methodology, we identified 20 fat-shaming events in the media; next, we obtained data from Project Implicit of participants who had completed the Weight Implicit Association Test from 2004 to 2015. As predicted, fat-shaming led to a spike in women's (N=93,239) implicit anti-fat attitudes, with events of greater notoriety producing greater spikes. We also observed a general increase in implicit anti-fat attitudes over time. Although these passing comments may appear harmless, we show that feedback at the cultural level can be registered by the ``body politic.''},
  langid = {english}
}

@article{ROTHERMUND2009,
  title = {Minimizing the Influence of Recoding in the {{Implicit Association Test}}: {{The Recoding-Free Implicit Association Test}} ({{IAT-RF}})},
  shorttitle = {Minimizing the Influence of Recoding in the {{Implicit Association Test}}},
  author = {Rothermund, Klaus and {Teige-Mocigemba}, Sarah and Gast, Anne and Wentura, Dirk},
  year = {2009},
  month = jan,
  journal = {Quarterly Journal of Experimental Psychology},
  volume = {62},
  number = {1},
  pages = {84--98},
  publisher = {{SAGE Publications}},
  issn = {1747-0218},
  doi = {10.1080/17470210701822975},
  abstract = {Recoding processes can influence the Implicit Association Test (IAT; Greenwald, McGhee, \& Schwartz, 1998) in a way that impedes an unequivocal interpretation of the resulting compatibility effects. We present a modified version of the IAT that aims to eliminate recoding, the IAT-RF (short for ``IAT\textendash recoding free''). In the IAT-RF, compatible and incompatible assignments of categories to responses switch randomly between trials within a single experimental block. Abandoning an extended sequence of consistent category\textendash response mappings undermines recoding processes in the IAT-RF. Two experiments reveal that the IAT-RF is capable of assessing compatibility effects between the nominally defined categories of the task and effectively prevents recoding. By enforcing a processing of the stimuli in terms of their task-relevant category membership, the IAT-RF eliminates the confounding of compatibility effects with task switch costs and becomes immune against biased selections of stimuli.},
  langid = {english}
}

@article{STEFFENS2001,
  title = {Items' {{Cross-Category Associations}} as a {{Confounding Factor}} in the {{Implicit Association Test}}},
  author = {Steffens, M. and Plewe, I.},
  year = {2001},
  month = apr,
  journal = {Zeitschrift f\"ur experimentelle Psychologie : Organ der Deutschen Gesellschaft f\"ur Psychologie},
  volume = {48},
  pages = {123--34},
  doi = {10.1026//0949-3946.48.2.123},
  abstract = {The introduction of the Implicit Association Test (IAT; Greenwald, McGhee, \& Schwartz, 1998) has stimulated numerous research activities. The IAT is supposed to measure the degree of association between concepts. Instances have to be assigned to these concepts by pressing appropriate keys as quickly as possible. The reaction time difference between certain conditions, termed the IAT effect, is used as an indicator of the degree of the concepts' association. We tested the hypothesis that the degree of association between one concept (or category) and the instances of the other presented concept also influences reaction times. In our experiment, the instances in the target categories, male and female names, were kept constant. The adjectives in the evaluative categories were manipulated: Either the pleasant adjectives were female-associated and the unpleasant adjectives were male-associated, or vice versa. These stereotypic associations were indeed found to exert a substantial influence on the size of the IAT effect. This finding casts doubt on the assumption that the IAT effect may be interpreted as a pure measure of the degree of association between concepts.}
}

@article{STEFFENS2005,
  title = {Implicit and {{Explicit Attitudes Towards Lesbians}} and {{Gay Men}}},
  author = {Steffens, M.},
  year = {2005},
  month = aug,
  journal = {Journal of Homosexuality},
  volume = {49},
  number = {2},
  pages = {39--66},
  publisher = {{Routledge}},
  issn = {0091-8369},
  doi = {10.1300/J082v49n02_03},
  abstract = {Attitudes towards lesbians and gay men, as assessed with questionnaires, have become more and more positive in the last decades. An open question is, however, whether that trend reflects true change or rather a growing reluctance to admit negative attitudes (to others and self). New procedures measuring implicit attitudes may help find an answer. In three studies with 208 students at a German university, attitudes towards lesbians and gay men were measured with explicit scales and with an Implicit Association Test (Greenwald, McGhee, \& Schwartz, 1998) adapted for that purpose. Explicit attitudes were very positive. However, implicit attitudes were relatively negative instead, except for female participants' implicit attitudes towards lesbians which were repeatedly as positive as were their attitudes towards heterosexuals. The internal consistencies of the implicit tests were exemplary. Correlations with sexual orientation as well as with explicit homosexuality-related and gender-related attitudes attested to their validity. However, context effects were found for different implicit attitudes measured in close succession, and correlations of implicit homosexuality-related and gender-related attitudes could not be detected.},
  pmid = {16048893},
  annotation = {\_eprint: https://doi.org/10.1300/J082v49n02\_03}
}

@article{TELLO2020,
  title = {Forecasting a {{Fatal Decision}}: {{Direct Replication}} of the {{Predictive Validity}} of the {{Suicide}}\textendash{{Implicit Association Test}}},
  shorttitle = {Forecasting a {{Fatal Decision}}},
  author = {Tello, Nina and {Harika-Germaneau}, Ghina and Serra, Wilfried and Jaafari, Nematollah and Chatard, Armand},
  year = {2020},
  month = jan,
  journal = {Psychological Science},
  volume = {31},
  number = {1},
  pages = {65--74},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1177/0956797619893062},
  abstract = {A previous study by Nock et al. (2010) suggested that people's implicit identification with ``death'' or ``suicide'' can accurately predict whether they will attempt suicide several months in advance. We report the first direct and independent replication of this promising finding. Participants were 165 patients seeking treatment at a psychiatric unit in France. At baseline, patients completed the Suicide\textendash Implicit Association Test (S\textendash IAT), a semistructured interview, and a self-report measure of suicide ideation. Six months later, we contacted participants by phone and examined their hospital medical records to determine whether they had made a new suicide attempt. Results showed that the S\textendash IAT did not distinguish between patients who were admitted to the hospital following suicide attempts and those who were admitted for other reasons. As in the original study, however, the S\textendash IAT predicted suicide attempts within the 6-month follow-up period beyond well-known predictors. The test correctly classified 85\% of patients (95\% confidence interval = [76.91, 91.53]), supporting its diagnostic value for identifying who will make a suicide attempt.},
  langid = {english}
}

@article{VANRAVENZWAAIJ2011,
  title = {Does the {{Name-Race Implicit Association Test Measure Racial Prejudice}}?},
  author = {{\noopsort{ravenzwaaij}}{van Ravenzwaaij}, Don and {\noopsort{maas}}{van der Maas}, Han L. J. and Wagenmakers, Eric-Jan},
  year = {2011},
  month = feb,
  journal = {Experimental Psychology},
  volume = {58},
  number = {4},
  pages = {271--277},
  publisher = {{Hogrefe Publishing}},
  issn = {1618-3169},
  doi = {10.1027/1618-3169/a000093},
  abstract = {Research using the Implicit Association Test (IAT) has shown that names labeled as Caucasian elicit more positive associations than names labeled as non-Caucasian. One interpretation of this result is that the IAT measures latent racial prejudice. An alternative explanation is that the result is due to differences in in-group/out-group membership. In this study, we conducted three different IATs: one with same-race Dutch names versus racially charged Moroccan names; one with same-race Dutch names versus racially neutral Finnish names; and one with Moroccan names versus Finnish names. Results showed equivalent effects for the Dutch-Moroccan and Dutch-Finnish IATs, but no effect for the Finnish-Moroccan IAT. This suggests that the name-race IAT-effect is not due to racial prejudice. A diffusion model decomposition indicated that the IAT-effects were caused by changes in speed of information accumulation, response conservativeness, and non-decision time.}
}

@article{WHITE2006,
  title = {Implicit and {{Explicit Occupational Gender Stereotypes}}},
  author = {White, Michael J. and White, Gwendolen B.},
  year = {2006},
  month = aug,
  journal = {Sex Roles},
  volume = {55},
  number = {3},
  pages = {259--266},
  issn = {1573-2762},
  doi = {10.1007/s11199-006-9078-z},
  abstract = {This study was designed to compare implicit and explicit occupational gender stereotypes for three occupations (engineer, accountant, and elementary school teacher). These occupations represented the end points and middle of a masculine\textendash feminine continuum of explicit occupational gender stereotypes. Implicit stereotypes were assessed using the Implicit Association Test (IAT), which is believed to minimize self-presentational biases common with explicit measures of occupational gender stereotypes. IAT results for the most gender stereotyped occupations, engineer (masculine) and elementary school teacher (feminine), were comparable to explicit ratings. There was less agreement with less stereotyped comparisons. Results indicated that accounting was implicitly perceived as more masculine than explicit measures indicate, which calls into question reports of diminishing gender stereotyping for such occupations.},
  langid = {english}
}

@article{WICHERTS2016,
  title = {Degrees of {{Freedom}} in {{Planning}}, {{Running}}, {{Analyzing}}, and {{Reporting Psychological Studies}}: {{A Checklist}} to {{Avoid}} p-{{Hacking}}},
  shorttitle = {Degrees of {{Freedom}} in {{Planning}}, {{Running}}, {{Analyzing}}, and {{Reporting Psychological Studies}}},
  author = {Wicherts, Jelte M. and Veldkamp, Coosje L. S. and Augusteijn, Hilde E. M. and Bakker, Marjan and {\noopsort{aert}}{van Aert}, Robbie C. M. and {\noopsort{assen}}{van Assen}, Marcel A. L. M.},
  year = {2016},
  journal = {Frontiers in Psychology},
  volume = {7},
  pages = {1832},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2016.01832},
  abstract = {The designing, collecting, analyzing, and reporting of psychological studies entail many choices that are often arbitrary. The opportunistic use of these so-called researcher degrees of freedom aimed at obtaining statistically significant results is problematic because it enhances the chances of false positive results and may inflate effect size estimates. In this review article, we present an extensive list of 34 degrees of freedom that researchers have in formulating hypotheses, and in designing, running, analyzing, and reporting of psychological research. The list can be used in research methods education, and as a checklist to assess the quality of preregistrations and to determine the potential for bias due to (arbitrary) choices in unregistered studies.}
}

@article{WOLSIEFER2017,
  title = {Modeling Stimulus Variation in Three Common Implicit Attitude Tasks},
  author = {Wolsiefer, Katie and Westfall, Jacob and Judd, Charles M.},
  year = {2017},
  month = aug,
  journal = {Behavior Research Methods},
  volume = {49},
  number = {4},
  pages = {1193--1209},
  issn = {1554-3528},
  doi = {10.3758/s13428-016-0779-0},
  abstract = {We explored the consequences of ignoring the sampling variation due to stimuli in the domain of implicit attitudes. A large literature in psycholinguistics has examined the statistical treatment of random stimulus materials, but the recommendations from this literature have not been applied to the social psychological literature on implicit attitudes. This is partly because of inherent complications in applying crossed random-effect models to some of the most common implicit attitude tasks, and partly because no work to date has demonstrated that random stimulus variation is in fact consequential in implicit attitude measurement. We addressed this problem by laying out statistically appropriate and practically feasible crossed random-effect models for three of the most commonly used implicit attitude measures\textemdash the Implicit Association Test, affect misattribution procedure, and evaluative~priming task\textemdash and then applying these models to large datasets (average N = 3,206) that assess participants' implicit attitudes toward race, politics, and self-esteem. We showed that the test statistics from the traditional analyses are substantially (about 60~\%) inflated relative to the more-appropriate analyses that incorporate stimulus variation. Because all three tasks used the same stimulus words and faces, we could also meaningfully compare the relative contributions of stimulus variation across the tasks. In an appendix, we give syntax in R, SAS, and SPSS for fitting the recommended crossed random-effects models to data from all three tasks, as well as instructions on how to structure the data file.},
  langid = {english}
}

@preamble{ "\providecommand{\noopsort}[1]{} " }
